{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset: \n",
    "https://www.kaggle.com/fivethirtyeight/the-ultimate-halloween-candy-power-ranking\n",
    "\n",
    "Tutorial:\n",
    "https://www.datacamp.com/courses/model-validation-in-python\n",
    "\n",
    "This project is about the model validation using random forest as an example.\n",
    "I compared the traditional train, cross-validation, and test set method and the Kfold method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from typing import List, Dict\n",
    "import re\n",
    "from typing import List, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.utils.fixes import signature\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_recall_curve, \\\n",
    "roc_auc_score, average_precision_score, mean_absolute_error, mean_squared_error, precision_score, make_scorer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.pipeline import Pipeline \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Traditional train, cross validation, and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_to_features_labels(df: pd.DataFrame, non_feature_list: List, label_list: List) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    \"\"\" Split the data into feature matrix and the labels vector\"\"\"\n",
    "    df_features = df.drop(non_feature_list, axis=1)\n",
    "    df_label = df[label_list]\n",
    "    return df_features, df_label\n",
    "\n",
    "def get_model_results_classification(X_train, y_train, X_test, y_test, model):\n",
    "    \"\"\"Train the model and evalute it\"\"\"\n",
    "\n",
    "    model.fit(X_train, np.ravel(y_train))\n",
    "    predicted = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predicted)\n",
    "    precision = precision_score(y_test, predicted, pos_label=\"positive\")\n",
    "    print('Accuracy: ', accuracy)\n",
    "    print('precision: ', precision)\n",
    "    print('Classification report \\n', classification_report(y_test, predicted))\n",
    "    print('Confusion matrix \\n', confusion_matrix(y_test, predicted))\n",
    "    return predicted, accuracy, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['competitorname', 'chocolate', 'fruity', 'caramel', 'peanutyalmondy',\n",
      "       'nougat', 'crispedricewafer', 'hard', 'bar', 'pluribus', 'sugarpercent',\n",
      "       'pricepercent', 'winpercent'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_original = pd.read_csv(\"candy-data.csv\")\n",
    "print(df_original.columns)\n",
    "\n",
    "df = df_original.copy()\n",
    "X, y = split_to_features_labels(df, non_feature_list=['winpercent', 'competitorname'], label_list=['winpercent'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary training and final testing datasets\n",
    "X_temp, X_test, y_temp, y_test  =\\\n",
    "    train_test_split(X, y, test_size=0.2, random_state=1111)\n",
    "\n",
    "# Create the final training and validation datasets\n",
    "X_train, X_val, y_train, y_val =\\\n",
    "    train_test_split(X_temp, y_temp, test_size=0.25, random_state=1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor()\n",
    "rfr.n_estimators = 100\n",
    "rfr.max_depth = 6\n",
    "rfr.random_state = 1111\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files (x86)\\python37-32\\lib\\site-packages\\ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=6,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "           oob_score=False, random_state=1111, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.42616758, 0.02322259, 0.03831592, 0.04979953, 0.01117358,\n",
       "       0.05099189, 0.00515225, 0.02361801, 0.02436229, 0.17341657,\n",
       "       0.17377979])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chocolate: 0.43\n",
      "fruity: 0.02\n",
      "caramel: 0.04\n",
      "peanutyalmondy: 0.05\n",
      "nougat: 0.01\n",
      "crispedricewafer: 0.05\n",
      "hard: 0.01\n",
      "bar: 0.02\n",
      "pluribus: 0.02\n",
      "sugarpercent: 0.17\n",
      "pricepercent: 0.17\n"
     ]
    }
   ],
   "source": [
    "# Print how important each column is to the model\n",
    "for i, item in enumerate(rfr.feature_importances_):\n",
    "      # Use i and item to print out the feature importance of each column\n",
    "    print(\"{0:s}: {1:.2f}\".format(X_train.columns[i], item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.687512835488868\n",
      "9.2037116475282\n",
      "21.03189610483642\n",
      "131.50787837403146\n"
     ]
    }
   ],
   "source": [
    "train_predictions = rfr.predict(X_train)\n",
    "val_predictions = rfr.predict(X_val)\n",
    "print(mean_absolute_error(y_true=y_train, y_pred=train_predictions))\n",
    "print(mean_absolute_error(y_true=y_val, y_pred=val_predictions))\n",
    "print(mean_squared_error(y_true=y_train, y_pred=train_predictions))\n",
    "print(mean_squared_error(y_true=y_val, y_pred=val_predictions))\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Top-Left', 'Top-Middle', 'Top-Right', 'Middle-Left', 'Middle-Middle',\n",
       "       'Middle-Right', 'Bottom-Left', 'Bottom-Middle', 'Bottom-Right',\n",
       "       'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original = pd.read_csv(\"tic-tac-toe.csv\")\n",
    "df_original.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_original.copy()\n",
    "X, y = split_to_features_labels(df, non_feature_list=['Class'], label_list=['Class'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numeric value by using the dummies\n",
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary training and final testing datasets\n",
    "X_temp, X_test, y_temp, y_test  =\\\n",
    "    train_test_split(X, y, test_size=0.2, random_state=1111)\n",
    "\n",
    "# Create the final training and validation datasets\n",
    "X_train, X_val, y_train, y_val =\\\n",
    "    train_test_split(X_temp, y_temp, test_size=0.25, random_state=1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set 1  underfitting, the tree is not deep enough\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(random_state=1111)\n",
    "rfc.n_estimators=50\n",
    "rfc.max_depth = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=6, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=None,\n",
      "            oob_score=False, random_state=1111, verbose=0,\n",
      "            warm_start=False)\n",
      "The random state is: 1111\n",
      "Printing the parameters dictionary: {'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_depth': 6, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 50, 'n_jobs': None, 'oob_score': False, 'random_state': 1111, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# get the parameter\n",
    "print(rfc)\n",
    "\n",
    "# Print the classification model's random state parameter\n",
    "print('The random state is: {}'.format(rfc.random_state))\n",
    "\n",
    "# Print all parameters\n",
    "print('Printing the parameters dictionary: {}'.format(rfc.get_params()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8854166666666666\n",
      "precision:  0.8671328671328671\n",
      "Classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.71      0.81        65\n",
      "    positive       0.87      0.98      0.92       127\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       192\n",
      "   macro avg       0.90      0.84      0.86       192\n",
      "weighted avg       0.89      0.89      0.88       192\n",
      "\n",
      "Confusion matrix \n",
      " [[ 46  19]\n",
      " [  3 124]]\n",
      "0.8854166666666666\n",
      "0.8854166666666666\n",
      "\n",
      " positive    143\n",
      "negative     49\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "predicted, accuracy, precision = get_model_results_classification(X_train, y_train, X_val, y_val, rfc)\n",
    "\n",
    "# accuracy for the cross validation set\n",
    "print(rfc.score(X_val, y_val))\n",
    "print(accuracy_score(y_val, rfc.predict(X_val)))\n",
    "\n",
    "# Print out count of binary predictions\n",
    "print('\\n', pd.Series(predicted).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.859375\n",
      "0.859375 \n",
      "\n",
      "[[ 37  23]\n",
      " [  4 128]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.62      0.73        60\n",
      "    positive       0.85      0.97      0.90       132\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       192\n",
      "   macro avg       0.88      0.79      0.82       192\n",
      "weighted avg       0.86      0.86      0.85       192\n",
      " \n",
      "\n",
      "The first predicted probabilities are: [0.19720733 0.80279267] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  evaluate the test set\n",
    "predicted_test = rfc.predict(X_test)\n",
    "\n",
    "print(rfc.score(X_test, y_test))\n",
    "print(accuracy_score(y_test, predicted_test), '\\n')\n",
    "print(confusion_matrix(y_test, predicted_test), '\\n')\n",
    "print(classification_report(y_test, predicted_test), '\\n')\n",
    "\n",
    "\n",
    "# Create arrays of predictions for test set. \n",
    "probability_predictions = rfc.predict_proba(X_test)\n",
    "print('The first predicted probabilities are: {}'.format(probability_predictions[0]), '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set 2 under fitting, not enough number of trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8697916666666666\n",
      "precision:  0.875\n",
      "Classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.74      0.79        65\n",
      "    positive       0.88      0.94      0.90       127\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       192\n",
      "   macro avg       0.87      0.84      0.85       192\n",
      "weighted avg       0.87      0.87      0.87       192\n",
      "\n",
      "Confusion matrix \n",
      " [[ 48  17]\n",
      " [  8 119]]\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(random_state=1111)\n",
    "rfc.n_estimators=10\n",
    "rfc.max_depth = 6\n",
    "predicted, accuracy, precision = get_model_results_classification(X_train, y_train, X_val, y_val, rfc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8697916666666666\n",
      "0.8697916666666666 \n",
      "\n",
      "[[ 38  22]\n",
      " [  3 129]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.63      0.75        60\n",
      "    positive       0.85      0.98      0.91       132\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       192\n",
      "   macro avg       0.89      0.81      0.83       192\n",
      "weighted avg       0.88      0.87      0.86       192\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  evaluate the test set\n",
    "predicted_test = rfc.predict(X_test)\n",
    "\n",
    "print(rfc.score(X_test, y_test))\n",
    "print(accuracy_score(y_test, predicted_test), '\\n')\n",
    "print(confusion_matrix(y_test, predicted_test), '\\n')\n",
    "print(classification_report(y_test, predicted_test), '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### set 3: increase the depth of the tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.96875\n",
      "precision:  0.9548872180451128\n",
      "Classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.91      0.95        65\n",
      "    positive       0.95      1.00      0.98       127\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       192\n",
      "   macro avg       0.98      0.95      0.96       192\n",
      "weighted avg       0.97      0.97      0.97       192\n",
      "\n",
      "Confusion matrix \n",
      " [[ 59   6]\n",
      " [  0 127]]\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(random_state=1111)\n",
    "rfc.n_estimators=50\n",
    "rfc.max_depth = 20\n",
    "predicted, accuracy, precision = get_model_results_classification(X_train, y_train, X_val, y_val, rfc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9791666666666666\n",
      "0.9791666666666666 \n",
      "\n",
      "[[ 56   4]\n",
      " [  0 132]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.93      0.97        60\n",
      "    positive       0.97      1.00      0.99       132\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       192\n",
      "   macro avg       0.99      0.97      0.98       192\n",
      "weighted avg       0.98      0.98      0.98       192\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  evaluate the test set\n",
    "predicted_test = rfc.predict(X_test)\n",
    "\n",
    "print(rfc.score(X_test, y_test))\n",
    "print(accuracy_score(y_test, predicted_test), '\\n')\n",
    "print(confusion_matrix(y_test, predicted_test), '\\n')\n",
    "print(classification_report(y_test, predicted_test), '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set 4: more features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9895833333333334\n",
      "precision:  0.9844961240310077\n",
      "Classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.97      0.98        65\n",
      "    positive       0.98      1.00      0.99       127\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       192\n",
      "   macro avg       0.99      0.98      0.99       192\n",
      "weighted avg       0.99      0.99      0.99       192\n",
      "\n",
      "Confusion matrix \n",
      " [[ 63   2]\n",
      " [  0 127]]\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(random_state=1111)\n",
    "rfc.n_estimators = 50\n",
    "rfc.max_depth = 20\n",
    "rfc.max_features = 20\n",
    "predicted, accuracy, precision = get_model_results_classification(X_train, y_train, X_val, y_val, rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9739583333333334\n",
      "0.9739583333333334 \n",
      "\n",
      "[[ 56   4]\n",
      " [  1 131]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.98      0.93      0.96        60\n",
      "    positive       0.97      0.99      0.98       132\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       192\n",
      "   macro avg       0.98      0.96      0.97       192\n",
      "weighted avg       0.97      0.97      0.97       192\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  evaluate the test set\n",
    "predicted_test = rfc.predict(X_test)\n",
    "\n",
    "print(rfc.score(X_test, y_test))\n",
    "print(accuracy_score(y_test, predicted_test), '\\n')\n",
    "print(confusion_matrix(y_test, predicted_test), '\\n')\n",
    "print(classification_report(y_test, predicted_test), '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loop to test many trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training scores were: [0.9, 0.88, 0.96, 0.97, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "The testing scores were: [0.7, 0.76, 0.83, 0.85, 0.89, 0.93, 0.98, 0.97, 0.97, 0.98]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xa455050>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_trees_list = [1, 2, 3, 4, 5, 10, 20, 50, 60, 80]\n",
    "test_scores, train_scores = [], []\n",
    "for i in num_trees_list:\n",
    "    rfc = RandomForestClassifier(n_estimators=i, random_state=1111)\n",
    "    rfc.fit(X_train, np.ravel(y_train))\n",
    "    # Create predictions for the X_train and X_test datasets.\n",
    "    train_predictions = rfc.predict(X_train)\n",
    "    val_predictions = rfc.predict(X_val)\n",
    "    # Append the accuracy score for the test and train predictions.\n",
    "    train_scores.append(round(accuracy_score(y_train, train_predictions), 2))\n",
    "    test_scores.append(round(accuracy_score(y_val, val_predictions), 2))\n",
    "# Print the train and test scores.\n",
    "print(\"The training scores were: {}\".format(train_scores))\n",
    "print(\"The testing scores were: {}\".format(test_scores))\n",
    "\n",
    "df_plot = pd.concat([pd.Series(train_scores), pd.Series(test_scores)], axis=1)\n",
    "df_plot.columns = ['train_scores', 'test_scores']\n",
    "df_plot.index = num_trees_list\n",
    "df_plot.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the problem of traditional train, test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "positive    134\n",
      "negative     66\n",
      "Name: Class, dtype: int64\n",
      "positive    123\n",
      "negative     77\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "tic_tac_toe = pd.read_csv(\"tic-tac-toe.csv\")\n",
    "# Create two different samples of 200 observations \n",
    "sample1 = tic_tac_toe.sample(200, random_state=1111)\n",
    "sample2 = tic_tac_toe.sample(200, random_state=1171)\n",
    "\n",
    "# Print the number of common observations \n",
    "print(len([index for index in sample1.index if index in sample2.index]))\n",
    "\n",
    "# Print the number of observations in the Class column for both samples \n",
    "print(sample1['Class'].value_counts())\n",
    "print(sample2['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If our models are not generalizing well or if we have limited data, we should be careful using a single \n",
    "# training/validation split. You should use the next lesson's topic: cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.1) use KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training indices: 54\n",
      "Number of validation indices: 14\n",
      "Split accuracy: 167.73866957411178\n",
      "Number of training indices: 54\n",
      "Number of validation indices: 14\n",
      "Split accuracy: 95.53148961183506\n",
      "Number of training indices: 54\n",
      "Number of validation indices: 14\n",
      "Split accuracy: 130.25635761522634\n",
      "Number of training indices: 55\n",
      "Number of validation indices: 13\n",
      "Split accuracy: 163.503258769309\n",
      "Number of training indices: 55\n",
      "Number of validation indices: 13\n",
      "Split accuracy: 159.25638660051754\n",
      "\n",
      " 143.25723243419995\n"
     ]
    }
   ],
   "source": [
    "df_original = pd.read_csv(\"candy-data.csv\")\n",
    "df = df_original.copy()\n",
    "X, y = split_to_features_labels(df, non_feature_list=['winpercent', 'competitorname'], label_list=['winpercent'])\n",
    "y = np.ravel(y)\n",
    "X = X.to_numpy()\n",
    "X_temp, X_test, y_temp, y_test  = train_test_split(X, y, test_size=0.2, random_state=1111)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=False, random_state=1111)\n",
    "splits = kf.split(X_temp)\n",
    "\n",
    "rfc = RandomForestRegressor(n_estimators=25, random_state=1111)\n",
    "\n",
    "# Access the training and validation indices of splits\n",
    "error_array = []\n",
    "for train_index, val_index in splits:\n",
    "    print(\"Number of training indices: %s\" % len(train_index))\n",
    "    print(\"Number of validation indices: %s\" % len(val_index))\n",
    "    # Setup the training and validation data\n",
    "    X_train, y_train = X_temp[train_index], y_temp[train_index]\n",
    "    X_val, y_val = X_temp[val_index], y_temp[val_index]\n",
    "    \n",
    "    rfc.fit(X_train, y_train)\n",
    "\n",
    "    predictions = rfc.predict(X_val)\n",
    "    error = mean_squared_error(y_val, predictions)\n",
    "    print(\"Split accuracy: \" + str(error))\n",
    "    error_array.append(error)\n",
    "    \n",
    "print('\\n', np.mean(error_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.2) use sklearn's cross_val_score()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[167.73866957  95.53148961 130.25635762 163.50325877 159.2563866 ]\n",
      "143.25723243419995\n"
     ]
    }
   ],
   "source": [
    "df_original = pd.read_csv(\"candy-data.csv\")\n",
    "df = df_original.copy()\n",
    "X, y = split_to_features_labels(df, non_feature_list=['winpercent', 'competitorname'], label_list=['winpercent'])\n",
    "y = np.ravel(y)\n",
    "X = X.to_numpy()\n",
    "X_temp, X_test, y_temp, y_test  = train_test_split(X, y, test_size=0.2, random_state=1111)\n",
    "\n",
    "\n",
    "rfc = RandomForestRegressor(n_estimators=25, random_state=1111)\n",
    "mse = make_scorer(mean_squared_error)\n",
    "\n",
    "# Set up cross_val_score\n",
    "cv = cross_val_score(estimator=rfc,\n",
    "                     X=X_temp,\n",
    "                     y=y_temp,\n",
    "                     cv=5,\n",
    "                     scoring=mse)\n",
    "\n",
    "# Print the mean error\n",
    "print(cv)\n",
    "print(cv.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave-one-out-cross-validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.90543183e-01 6.92920425e+02 1.11787314e+02 2.30869627e+02\n",
      " 1.46528984e+02 2.55470743e+02 1.76068084e+02 2.18034723e+02\n",
      " 5.47226985e-01 9.27087887e+01 6.44558479e+02 9.81079686e+01\n",
      " 6.13625697e+02 3.49029728e-01 2.81303652e-01 8.27226816e+01\n",
      " 3.14097753e+00 3.06427865e+00 1.71765407e+02 3.69309107e+01\n",
      " 1.22920270e+01 1.20663383e+02 1.79614566e+02 2.38034036e+01\n",
      " 2.00498747e+00 8.86263498e+00 2.90797904e+02 1.00674708e+02\n",
      " 5.52211032e+02 5.09115540e+00 2.32292865e+01 1.03227747e+02\n",
      " 4.06608367e+00 9.36373415e+00 6.52522271e+00 2.25397399e+00\n",
      " 1.55018596e+02 5.54894721e+00 1.10063538e+01 1.38492996e+02\n",
      " 6.96092513e+00 1.15460655e+02 1.44391558e+02 2.63546523e+01\n",
      " 4.77070072e+02 9.37687348e+01 1.44636065e+02 1.93501864e+01\n",
      " 1.81247894e+00 1.26072965e+01 1.12332436e+02 9.05971802e+02\n",
      " 1.83062278e+02 2.48601273e+02 1.19549978e-01 6.21624031e+00\n",
      " 2.89602861e+01 8.14911516e+01 4.76245441e+01 3.23579597e+02\n",
      " 1.24708504e+02 2.56965968e+00 3.95071710e+02 5.76635297e+00\n",
      " 4.68033939e+01 1.84400149e+02 1.50428626e+02 5.22051296e-01\n",
      " 8.49895147e+02 4.68867172e+01 2.50802424e+02 5.85700780e+01\n",
      " 5.07001519e+02 2.32472986e+02 3.70968818e+01 1.86150795e+02\n",
      " 8.27637800e+00 5.89068930e+00 1.09646155e+00 3.01548002e+02\n",
      " 3.72749978e+01 9.68136959e-01 1.10516711e+01 5.24398793e+01\n",
      " 2.90874721e+02]\n",
      "142.39837236565708\n",
      "194.6922348182418\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestRegressor(n_estimators=25, random_state=1111)\n",
    "mse = make_scorer(mean_squared_error)\n",
    "\n",
    "# Set up cross_val_score\n",
    "cv = cross_val_score(estimator=rfc,\n",
    "                     X=X,\n",
    "                     y=y,\n",
    "                     cv=X.shape[0],\n",
    "                     scoring=mse)\n",
    "\n",
    "# Print the mean error\n",
    "print(cv)\n",
    "print(cv.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) RandomizedSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files (x86)\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "          estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "           oob_score=False, random_state=1111, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=10, n_jobs=None,\n",
       "          param_distributions={'max_depth': [2, 4, 6, 8], 'max_features': [2, 4, 6, 8, 10], 'min_samples_split': [2, 4, 8, 16]},\n",
       "          pre_dispatch='2*n_jobs', random_state=1111, refit=True,\n",
       "          return_train_score='warn',\n",
       "          scoring=make_scorer(mean_squared_error), verbose=0)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the data\n",
    "df = pd.read_csv(\"candy-data.csv\")\n",
    "X, y = split_to_features_labels(df, non_feature_list=['winpercent', 'competitorname'], label_list=['winpercent'])\n",
    "y = np.ravel(y)\n",
    "X = X.to_numpy()\n",
    "X_temp, X_test, y_temp, y_test  = train_test_split(X, y, test_size=0.2, random_state=1111)\n",
    "\n",
    "# Set parameters\n",
    "scorer = make_scorer(mean_squared_error)\n",
    "param_dist = {\"max_depth\": [2, 4, 6, 8],\n",
    "              \"max_features\": [2, 4, 6, 8, 10],\n",
    "              \"min_samples_split\": [2, 4, 8, 16]}\n",
    "rfr = RandomForestRegressor(n_estimators=10, random_state=1111)\n",
    "\n",
    "rs = RandomizedSearchCV(estimator=rfr, \n",
    "                        param_distributions=param_dist,\n",
    "                        scoring = scorer,\n",
    "                        cv=5, \n",
    "                        n_iter=10, \n",
    "                        random_state=1111)\n",
    "\n",
    "rs.fit(X_temp, y_temp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_test_score =  [139.77362145 145.75417836 147.98647683 149.54197624 136.55358739\n",
      " 125.25619705 142.71851263 146.39508123 155.46220574 128.11277612] \n",
      "\n",
      "best_score =  155.46220573794935 \n",
      "\n",
      "best_params =  {'min_samples_split': 2, 'max_features': 10, 'max_depth': 2} \n",
      "\n",
      "params [{'min_samples_split': 8, 'max_features': 6, 'max_depth': 6}, {'min_samples_split': 16, 'max_features': 10, 'max_depth': 4}, {'min_samples_split': 16, 'max_features': 10, 'max_depth': 2}, {'min_samples_split': 8, 'max_features': 10, 'max_depth': 6}, {'min_samples_split': 4, 'max_features': 8, 'max_depth': 4}, {'min_samples_split': 4, 'max_features': 4, 'max_depth': 8}, {'min_samples_split': 8, 'max_features': 10, 'max_depth': 4}, {'min_samples_split': 16, 'max_features': 10, 'max_depth': 6}, {'min_samples_split': 2, 'max_features': 10, 'max_depth': 2}, {'min_samples_split': 2, 'max_features': 8, 'max_depth': 8}] \n",
      "\n",
      "max_depth =  [6, 4, 2, 6, 4, 8, 4, 6, 2, 8] \n",
      "\n",
      "                Score\n",
      "Max Depth            \n",
      "2.0        151.724341\n",
      "4.0        141.675426\n",
      "6.0        145.236893\n",
      "8.0        126.684487 \n",
      "\n",
      "score of the model 96.6981349443\n"
     ]
    }
   ],
   "source": [
    "mean_test_score = rs.cv_results_['mean_test_score']\n",
    "print('mean_test_score = ', mean_test_score, '\\n')\n",
    "print('best_score = ', rs.best_score_, '\\n')\n",
    "print('best_params = ', rs.best_params_, '\\n')\n",
    "print('params', rs.cv_results_['params'], '\\n')\n",
    "\n",
    "# Max_depth vs params table\n",
    "max_depth = [item['max_depth'] for item in rs.cv_results_['params']]\n",
    "print('max_depth = ', max_depth, '\\n')\n",
    "scores = list(rs.cv_results_['mean_test_score'])\n",
    "d = pd.DataFrame([max_depth, scores]).T\n",
    "d.columns = ['Max Depth', 'Score']\n",
    "print(d.groupby(['Max Depth']).mean(), '\\n')\n",
    "\n",
    "# score of the model, can compare to other model\n",
    "print('score of the model', rs.score(X_temp, y_temp))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_estimator_ =  RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
      "           max_features=10, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=10, n_jobs=None, oob_score=False,\n",
      "           random_state=1111, verbose=0, warm_start=False) \n",
      "\n",
      "{'bootstrap': True, 'criterion': 'mse', 'max_depth': 2, 'max_features': 10, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 1111, 'verbose': 0, 'warm_start': False} \n",
      "\n",
      "9.652357768195126\n"
     ]
    }
   ],
   "source": [
    "print('best_estimator_ = ', rs.best_estimator_, '\\n')\n",
    "print(rs.best_estimator_.get_params(), '\\n')\n",
    "\n",
    "\n",
    "predicted = rs.best_estimator_.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_true=y_test, y_pred=predicted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model for use later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rfr_best_2019.5.21.pkl']"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rs, 'rfr_best_2019.5.21.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files (x86)\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=1111, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=10, n_jobs=None,\n",
       "          param_distributions={'max_depth': [2, 4, 6, 8], 'max_features': [2, 4, 6, 8, 10], 'min_samples_split': [2, 4, 8, 16]},\n",
       "          pre_dispatch='2*n_jobs', random_state=1111, refit=True,\n",
       "          return_train_score='warn', scoring=make_scorer(precision_score),\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the data\n",
    "df = pd.read_csv(\"tic-tac-toe.csv\")\n",
    "X, y = split_to_features_labels(df, non_feature_list=['Class'], label_list=['Class'])\n",
    "X = pd.get_dummies(X)\n",
    "y = np.ravel(np.where(y =='positive', 1, 0))\n",
    "X_temp, X_test, y_temp, y_test  = train_test_split(X, y, test_size=0.2, random_state=1111)\n",
    "\n",
    "\n",
    "# Set the parameters\n",
    "precision = make_scorer(precision_score)\n",
    "param_dist = {\"max_depth\": [2, 4, 6, 8],\n",
    "              \"max_features\": [2, 4, 6, 8, 10],\n",
    "              \"min_samples_split\": [2, 4, 8, 16]}\n",
    "rfc = RandomForestClassifier(n_estimators=10, random_state=1111)\n",
    "\n",
    "\n",
    "rs = RandomizedSearchCV(estimator=rfc, \n",
    "                        param_distributions=param_dist,\n",
    "                        scoring = precision,\n",
    "                        cv=5, \n",
    "                        n_iter=10, \n",
    "                        random_state=1111)\n",
    "\n",
    "rs.fit(X_temp, y_temp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_test_score =  [0.84082907 0.78830425 0.70264725 0.8828238  0.76684    0.8988839\n",
      " 0.78932828 0.87218418 0.70264725 0.93442478] \n",
      "\n",
      "best_score =  0.9344247778769172 \n",
      "\n",
      "best_params =  {'min_samples_split': 2, 'max_features': 8, 'max_depth': 8} \n",
      "\n",
      "params [{'min_samples_split': 8, 'max_features': 6, 'max_depth': 6}, {'min_samples_split': 16, 'max_features': 10, 'max_depth': 4}, {'min_samples_split': 16, 'max_features': 10, 'max_depth': 2}, {'min_samples_split': 8, 'max_features': 10, 'max_depth': 6}, {'min_samples_split': 4, 'max_features': 8, 'max_depth': 4}, {'min_samples_split': 4, 'max_features': 4, 'max_depth': 8}, {'min_samples_split': 8, 'max_features': 10, 'max_depth': 4}, {'min_samples_split': 16, 'max_features': 10, 'max_depth': 6}, {'min_samples_split': 2, 'max_features': 10, 'max_depth': 2}, {'min_samples_split': 2, 'max_features': 8, 'max_depth': 8}] \n",
      "\n",
      "max_depth =  [6, 4, 2, 6, 4, 8, 4, 6, 2, 8] \n",
      "\n",
      "              Score\n",
      "Max Depth          \n",
      "2.0        0.702647\n",
      "4.0        0.781491\n",
      "6.0        0.865279\n",
      "8.0        0.916654 \n",
      "\n",
      "score of the model 1.0\n"
     ]
    }
   ],
   "source": [
    "mean_test_score = rs.cv_results_['mean_test_score']\n",
    "print('mean_test_score = ', mean_test_score, '\\n')\n",
    "print('best_score = ', rs.best_score_, '\\n')\n",
    "print('best_params = ', rs.best_params_, '\\n')\n",
    "print('params', rs.cv_results_['params'], '\\n')\n",
    "\n",
    "# Max_depth vs params table\n",
    "max_depth = [item['max_depth'] for item in rs.cv_results_['params']]\n",
    "print('max_depth = ', max_depth, '\\n')\n",
    "scores = list(rs.cv_results_['mean_test_score'])\n",
    "d = pd.DataFrame([max_depth, scores]).T\n",
    "d.columns = ['Max Depth', 'Score']\n",
    "print(d.groupby(['Max Depth']).mean(), '\\n')\n",
    "\n",
    "# score of the model, can compare to other model\n",
    "print('score of the model', rs.score(X_temp, y_temp))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_estimator_ =  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=8, max_features=8, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=1111, verbose=0,\n",
      "            warm_start=False) \n",
      "\n",
      "{'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_depth': 8, 'max_features': 8, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': 1111, 'verbose': 0, 'warm_start': False} \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95        60\n",
      "           1       0.97      0.98      0.98       132\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       192\n",
      "   macro avg       0.97      0.96      0.96       192\n",
      "weighted avg       0.97      0.97      0.97       192\n",
      "\n",
      "0.96875\n"
     ]
    }
   ],
   "source": [
    "print('best_estimator_ = ', rs.best_estimator_, '\\n')\n",
    "print(rs.best_estimator_.get_params(), '\\n')\n",
    "\n",
    "\n",
    "predicted = rs.best_estimator_.predict(X_test)\n",
    "\n",
    "print(classification_report(y_true=y_test, y_pred=predicted))\n",
    "print(accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
